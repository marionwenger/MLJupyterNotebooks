{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZEco2HK6D57"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3nCUqopXHwv"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0xdeadbeef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjTkUw7BWulH"
   },
   "source": [
    "# Lab 02: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNnZUk36Xz7_"
   },
   "source": [
    "For the first tasks, we will work with synthetic univariate data.\n",
    "We generate $100$ features $x_i \\in [-1, 1]$ as `x` and two different\n",
    "regression targets `y1` and `y2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ojta777H2ulb"
   },
   "outputs": [],
   "source": [
    "data_rng = np.random.default_rng(RANDOM_SEED)\n",
    "n = 100\n",
    "x = 2 * data_rng.random(n) - 1  # create n points between -1 and 1\n",
    "\n",
    "# setup synthetic y1\n",
    "true_offset = 0.5\n",
    "true_slope = 1.25\n",
    "noise = data_rng.normal(loc=0., scale=0.25, size=(n,))\n",
    "\n",
    "y1 = true_offset + true_slope * x + noise\n",
    "\n",
    "\n",
    "# setup synthetic y2\n",
    "y2  = true_offset + np.sin(np.pi * x) + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntdpTWzqZqAU"
   },
   "source": [
    "# Task 1: Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbNJ7WhzbAtm"
   },
   "source": [
    "In the next cell, we show you how you can use `plt.scatter` to create scatter-plots.\n",
    "\n",
    "A scatter plot is a graphical representation that displays individual data points based on two variables, with one variable plotted along the x-axis and the other plotted along the y-axis. It's commonly used to observe and show relationships between two numeric variables.\n",
    "Plot `x` against the target variable `y1`.\n",
    "\n",
    "The simplest way to create a scatter-plot in `matplotlib` is by calling `plt.scatter(x, y)` where `x` is a list or array of x-coordinates and `y` is a list or array of y-coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgN-CimVK9vl"
   },
   "outputs": [],
   "source": [
    "# Let us create a scatter-plot of x and y1\n",
    "plt.scatter(x, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5njACsM7LOMp"
   },
   "source": [
    "In the next cell, we re-create the same plot but also label the axes, which is generally a good practice.\n",
    "\n",
    "In `matplotlib` it is common to build a plot incrementally by calling many functions (such as `plt.xlabel` and `plt.ylabel` here), before displaying the result using `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxYMdhfxyYAd"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y1)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFTpeQMrL4mx"
   },
   "source": [
    "## ðŸš¨ Task 1A (1 Point) ðŸš¨\n",
    "\n",
    "Your turn:\n",
    "\n",
    "* create a scatter-plot of `x` and `y2`.\n",
    "* Study the plot: do you think the relationship between `x` and `y2` is linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpzwoBdQDd-d"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VBXqkBMczI1"
   },
   "source": [
    "\n",
    "\n",
    "* Report whether the relationship between `x` and `y2` is linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbjhdwFceHlL"
   },
   "source": [
    "# Task 2: Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucnYGKbmecz_"
   },
   "source": [
    "You will now implement Linear Regression with a single variable. In class you have seen that the underlying model is: $y = \\theta_0 + \\theta_1x$.\n",
    "\n",
    "You also derived the closed formula for $\\theta_0$ and $\\theta_1$:\n",
    "\n",
    "* $\\hat{\\theta}_1 = \\frac{\\sum_{i=1}^{m} (x_i - \\mu(x))(y_i - \\mu(y))}{\\sum_{i=1}^{m}(x_i - \\mu(x))^2}$\n",
    "* $\\hat{\\theta}_0 = \\mu(y) - \\hat{\\theta}_1\\mu(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlMsQokKdksd"
   },
   "source": [
    "## ðŸš¨ Task 2A (2 Points) ðŸš¨\n",
    "\n",
    "In the following cell, implement the `.fit` and `.predict` methods:\n",
    "* In the `.predict` method you will have to apply the model to the input `x`\n",
    "* In the `.fit` method you will have to compute $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS0Oa5Btgk74"
   },
   "outputs": [],
   "source": [
    "class UnivariateLinearRegression:\n",
    "\n",
    "  def __init__(self):\n",
    "    self.theta_0: float = 0.\n",
    "    self.theta_1: float = 0.\n",
    "\n",
    "  def predict(self, x):\n",
    "    y_pred = ...  # TODO\n",
    "    return y_pred\n",
    "\n",
    "  def fit(self, x, y):\n",
    "    # TODO\n",
    "    self.theta_0 = ...\n",
    "    self.theta_1 = ...\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySKlBT7dd1hS"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LzenH1UhLOs"
   },
   "source": [
    "Now we fit the linear model to `x` and the target `y1`:\n",
    "\n",
    "* Create an instance of the class `UnivariateLinearRegression`\n",
    "* fit the model using its `.fit` method\n",
    "* get the predicted values, using `.predict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdIrwBLG1I_8"
   },
   "outputs": [],
   "source": [
    "lin_reg_uni = UnivariateLinearRegression()\n",
    "lin_reg_uni.fit(x, y1)\n",
    "y_pred = lin_reg_uni.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elE3OfjHjBRO"
   },
   "source": [
    "In the next cell, we provide a helper function to visualize your fitted linear model, based on `x`, the true values of `y` (`y_true`) and the predicted values of `y` (`y_pred`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0eKDuRt1YOF"
   },
   "outputs": [],
   "source": [
    "def plot_model(x, y_pred, y_true):\n",
    "  # scatter plot of the true data points\n",
    "  plt.scatter(x, y_true)\n",
    "  # plot the fitted line\n",
    "  plt.plot(x, y_pred, c=\"r\")\n",
    "  # label axes\n",
    "  plt.xlabel(\"x\")\n",
    "  plt.ylabel(\"y\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwxsx5lGOx3O"
   },
   "source": [
    "We use `plot_model` to visualize to outcome of our linear regression for `x` and `y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2goCBVKLPBHm"
   },
   "outputs": [],
   "source": [
    "plot_model(x=x, y_pred=y_pred, y_true=y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt2RnAwAG1n9"
   },
   "source": [
    "Now we repeat the same steps for `x` and `y2`. Inspect the plot and reflect on your answer to Task 2A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ccq3GI17Ga2x"
   },
   "outputs": [],
   "source": [
    "lin_reg_uni = UnivariateLinearRegression()\n",
    "lin_reg_uni.fit(x, y2)\n",
    "y_pred = lin_reg_uni.predict(x)\n",
    "\n",
    "plot_model(x, y_pred, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta5zAjsuQFlR"
   },
   "source": [
    "# Task 3: Multivariate Linear Regression using the Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgVABRUlWwo6"
   },
   "source": [
    "In the next cell, we provide a function to generate synthetic data for\n",
    "multivariate linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEm4eB2GS1gJ"
   },
   "outputs": [],
   "source": [
    "def create_random_data(m: int, n: int, random_seed: int = RANDOM_SEED):\n",
    "  \"\"\"\n",
    "  m: number of samples\n",
    "  n: number of dimensions\n",
    "  random_seed: seed to initialize random number generator\n",
    "  \"\"\"\n",
    "  rng = np.random.default_rng(random_seed)\n",
    "  # random data\n",
    "  X = rng.standard_normal(size=(m, n))\n",
    "  # random true model parameters\n",
    "  theta = rng.standard_normal(n)\n",
    "  # random noise\n",
    "  noise = rng.normal(loc=0., scale=.25, size=m)\n",
    "  # observed y values\n",
    "  y = X @ theta + noise\n",
    "  return X, y\n",
    "\n",
    "# create synthetic dataset with 100 observations and 10 dimensions\n",
    "X, y = create_random_data(100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72ecXwtMXorm"
   },
   "source": [
    "In class you have seen that the underlying model for multivariate linear regression is: $y = X\\theta$. Here $X \\in \\mathbb{R}^{m, n}$, $\\theta \\in \\mathbb{R}^{n}$, and $y \\in \\mathbb{R}^{m}$.\n",
    "\n",
    "We also derived a closed formula for $\\theta$:\n",
    "\n",
    " $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}y$\n",
    "\n",
    "This is known as the *normal equation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDb5iT2DbCQT"
   },
   "source": [
    "The normal equation can be used to solve univariate and also multivariate linear regression problems, and we have shown that it yields optimal parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dw4O4zzblU7"
   },
   "source": [
    "In the next cell we implement the normal equation $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}y$ and apply it to our data `X` and `y`.\n",
    "\n",
    "`numpy` reminder:\n",
    "* the transpose of `X` is written `X.T`\n",
    "* matrix multiplication is written with the `@` symbol, e.g. `A @ B`.\n",
    "* you can compute the inverse of a matrix `A` using `np.linalg.inv(A)`. However, it is more numerically stable (and yes, this can really make a difference in practice!) to use a method such as `pinv` or `solve`, as noted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6Af3VQ-Tqco"
   },
   "outputs": [],
   "source": [
    "theta = (np.linalg.inv(X.T @ X) @ X.T) @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0CvpicyfLi5"
   },
   "source": [
    "*Computing the matrix inverse as part of a larger expression*: when solving the normal equation, we don't actually care about the inverse $(X^{T}X)^{-1}$ by itself; rather, we care about its value <em>when multiplied by another vector</em>. In particular, the expression $(X^{T}X)^{-1}X^{T}$ is also known as the [Moore-Penrose Pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) of $X$ and can be computed directly using `np.linalg.pinv(X)`, which is generally more efficient. Alternatively, you can solve the normal equation as `np.linalg.solve(X.T @ X, X.T @ y)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozPqV-ekc3sX"
   },
   "source": [
    "In the next cell, we provide a helper function to create a residual plot\n",
    "based on the true values of `y` (`y_true`) and the predicted values of `y` (`y_pred`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hjDkSzedCVc"
   },
   "outputs": [],
   "source": [
    "def residual_plot(y_true, y_pred):\n",
    "  residual = y_pred - y_true\n",
    "  plt.scatter(y_true, residual)\n",
    "  plt.xlabel(\"y\")\n",
    "  plt.ylabel(\"residual\")\n",
    "  plt.title(\"Residual Plot\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPgYF6W2damr"
   },
   "source": [
    "Below we compute the predicted values of `y` based on the value of $\\theta$ you computed using the normal equation. Then we plot the residuals using `residual_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1r2mDlCdQNs"
   },
   "outputs": [],
   "source": [
    "y_pred = X @ theta\n",
    "\n",
    "residual_plot(y_true=y, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIQLVzb3gwAR"
   },
   "source": [
    "## Performance of Normal Equation\n",
    "\n",
    "Max Clever has seen the slides for next lecture already â€“ where we will discuss alternative methods such as \"gradient descent\" for linear regression.\n",
    "\n",
    "Now he wonders: *Why do we need other algorithms, when the normal equation solves the problem already?*\n",
    "\n",
    "To answer this question, we will now explore how the runtime of computing the normal equation depends on the input size $n$ and $m$.\n",
    "\n",
    "In the next cell, we provide a skeleton to measure the runtime of computing the normal equation depending on the problem size n*m.\n",
    "\n",
    "## ðŸš¨ Task 3A (2 Point) ðŸš¨\n",
    "* fill in the blanks in the code below\n",
    "* run the code and explore different values for $m$. For which values of $m$ is the running time still below 30min?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FZizKeAob-n"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "sizes = []\n",
    "times = []\n",
    "n = 1000\n",
    "for m in [10, 50, 100, 200, 250, 500, 1000]:\n",
    "  X, y = ... # TODO create a dataset with m samples and n dimensions, we provide a helper function for this!\n",
    "\n",
    "  start_time = time.monotonic()\n",
    "  # enter the code you want to time here\n",
    "  elapsed = time.monotonic() - start_time\n",
    "\n",
    "  problem_size = ...  # TODO what is the input size of the problem\n",
    "\n",
    "  sizes.append(problem_size)\n",
    "  times.append(elapsed)\n",
    "\n",
    "plt.scatter(sizes, times)\n",
    "plt.xlabel('Problem-Size')\n",
    "plt.ylabel('Runtime (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzn9IONOhZvx"
   },
   "source": [
    "\n",
    "* Plot with different problem sizes\n",
    "* Which problem size yields a running time of approximately 30 minutes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx-di2EypWy6"
   },
   "source": [
    "## ðŸš¨ Task 3B (2 Point) ðŸš¨\n",
    "\n",
    "We now explore the impact of the number of features, $n$, on the running time:\n",
    "\n",
    "* Modify your solution to Task 3A to measure the runtime dependence on the number of features $n$ instead of the number of samples $m$.\n",
    "* What happens if you use large values for $n$, e.g. $n = 100'000$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cttPLHu6prPH"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnwQb2JKpwL_"
   },
   "source": [
    "\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "* Upload your plot with a \"very large\" maximal value for $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBAW0JCgrCGf"
   },
   "source": [
    "## OPTIONAL QUESTIONS\n",
    "\n",
    "* Do your responses to Tasks 3A and 3B change if you use `np.linalg.pinv(X)`?\n",
    "* Probably your plots for number of samples $m$ and number of features $n$ look very alike. Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgrNtwsPyigH"
   },
   "source": [
    "# Task 4: Multivariate Linear Regression using `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sPWegXCg2y1"
   },
   "source": [
    "In this task we will apply linear regression to non-synthetic data.\n",
    "The variable `X` is a `pandas` `Dataframe` containing features and `y` contains\n",
    "the target. Read through the description to get an idea of the different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djGUQ3kVx9ob"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "description = data['DESCR']\n",
    "\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byOVt9t9_2c7"
   },
   "source": [
    "In the next cell, we will fit a linear regression model on this diabetes dataset\n",
    "using the implementation provided by the popular `scikit-learn` library.\n",
    "\n",
    "Their [implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) is contained in the `sklearn.linear_model.LinearRegression` class. The most important methods of any `sklearn` model are `.fit` and `.predict`. You will see them a lot in future labs.\n",
    "\n",
    "The `.fit(X, y)` method trains the linear regression model and `.predict(X)` return the model's predictions for the data `X`.\n",
    "\n",
    "You can see them in action in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4AktC189PAc"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "y_pred = lin_reg.predict(X)\n",
    "\n",
    "residual_plot(y_true=y, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQUdYHOXpeLd"
   },
   "source": [
    "The numeric entries of the estimated parameter vector $\\theta$ tell us something about the strength and direction of the relationship between the variables in `X` and the target `y`.\n",
    "\n",
    "\n",
    "The estimated parameters $\\theta$ of the linear model can be found in the `.coef_` member variable. The feature names can be found in the `.feature_names_in_` member variable. They are the same as the names of the columns of `X` and should be in the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8pyPAMwl5c-"
   },
   "source": [
    "In the next code cell, we will plot the entries of $\\theta$ paired with their corresponding feature name. We will also print out the same information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J8vO5FemPQw"
   },
   "source": [
    "## ðŸš¨ Task 4A (3 Points) ðŸš¨\n",
    "\n",
    "Study the plot and printed output of the next cell and answer the following questions:\n",
    "\n",
    "* Which are the 3 most influential features?\n",
    "* How do you interpret the sign of the coefficients?\n",
    "* If you had to exclude 1 feature, which one would you select and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odXnubfHqrfc"
   },
   "outputs": [],
   "source": [
    "thetas = lin_reg.coef_\n",
    "feature_names = lin_reg.feature_names_in_\n",
    "\n",
    "plt.bar(feature_names, thetas)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"theta\")\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "for th, name in zip(thetas, feature_names):\n",
    "  print(f\"{name}\\t{th}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmrnK-EkmgFW"
   },
   "source": [
    "\n",
    "\n",
    "* Report your answers to the 3 questions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
